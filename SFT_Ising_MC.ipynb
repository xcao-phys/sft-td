{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BEGIN\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc('font', **{ \"size\":16}) #**{,,'serif':['Palatino']\n",
    "rc('text', usetex=True)\n",
    "import numpy.random as rnd\n",
    "rnd.seed()\n",
    "import scipy.sparse as sp\n",
    "import scipy.sparse.linalg as sla\n",
    "import scipy.linalg as la\n",
    "import pickle as cp\n",
    "import scipy.optimize as opt\n",
    "from scipy.optimize import curve_fit as fit\n",
    "#import mps\n",
    "import cProfile\n",
    "import subprocess\n",
    "from scipy.special import hyp2f1, erf\n",
    "from scipy.optimize import brentq\n",
    "from matplotlib import cm\n",
    "cmap = cm.get_cmap(\"tab20\")\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_graph(L, cut_boundary = 0, **kwargs):\n",
    "    xy2i = lambda x,y:x*L + y\n",
    "    xs, ys =  np.arange(L**2) // L, np.arange(L**2) % L\n",
    "    xp, xm = (xs + 1) % L, (xs - 1) % L\n",
    "    yp, ym = (ys + 1) % L, (ys - 1) % L\n",
    "\n",
    "\n",
    "    matrix = sp.coo_matrix((L**2, L**2), dtype= int)\n",
    "    inds = np.array([ xy2i(xp, ys), xy2i(xm, ys), \n",
    "                     xy2i(xs , yp), xy2i(xs, ym)]).T.reshape(-1)\n",
    "    data = np.ones_like(inds, dtype=int)\n",
    "    indptr = np.arange(L ** 2 + 1) * 4\n",
    "    full_graph = sp.csc_matrix((data, inds, indptr),shape=(L**2, L**2))\n",
    "\n",
    "    ## cut all the boundaries\n",
    "    if 0:\n",
    "        lil = full_graph.tolil()\n",
    "        lil[:L, -L:] = 0\n",
    "        lil[-L:, :L] = 0\n",
    "        lil[::L, L-1::L] = 0\n",
    "        lil[L-1::L, ::L] = 0\n",
    "        full_graph = lil.tocsc()\n",
    "    ##############\n",
    "\n",
    "    edges = sp.coo_matrix(full_graph)\n",
    "    ut_ind = edges.row > edges.col\n",
    "    edges = sp.coo_matrix((edges.data[ut_ind], (edges.row[ut_ind], edges.col[ut_ind])), shape = (L**2,L**2))\n",
    "    #degree = np.diff(full_graph.indptr)\n",
    "    return full_graph, edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ising model on the square lattice\n",
    "\n",
    "We will study numerically the Ising model on a 2D square lattice, using the Swendsen-Wang Monte Carlo algorithm. It is based on the Fortuin-Kasterleyn (FK) representation of the Ising model, which is interesting in its own right.\n",
    "\n",
    "## Preparation: what is the critical temperature?\n",
    "\n",
    "- Recall the high-$T$ and low-$T$ expansions of the Ising model on the 2D square lattice, whose partition function is \n",
    "$$ Z = \\sum_{\\{\\sigma\\} } \\exp\\left(\\sum_{\\left<ij\\right>} K \\sigma_i \\sigma_j \\right) \\,.$$\n",
    "Here $K=\\beta J$ is the dimensionless temperature.\n",
    "\n",
    "- Deduce the Kramers-Wagner duality relation, and identify the self-dual point $K_c$ as satisfying \n",
    "$$ e^{-2K_c} = \\sqrt{2} - 1 \\,. $$\n",
    "This is the critical inverse temperature. \n",
    "\n",
    "##  Fortuin-Kasterleyn (FK) representation\n",
    "\n",
    "This is a slightly different high-$T$ expansion of the Ising model. One starts by rewriting the Boltzmann weight on a bond as follows\n",
    "$$ e^{K \\sigma \\sigma'} \\propto (1 + x \\delta_{\\sigma, \\sigma'}) \\,,\\, x = e^{2K}-1 $$\n",
    "Doing this for all bonds, we obtain an expansion of the partition function as a sum of \"FK cluster\" configurations. \n",
    "\n",
    "- Show that the relative weight of a FK cluster configuration is \n",
    "$$ w^{\\text{number of active bonds}} (1-w)^{\\text{number of inactive bonds}} Q^{\\text{number of clusters}} $$\n",
    "where \n",
    "$$ w = \\frac{x}{1+x} = 1-e^{-2K} $$\n",
    "and $$Q = 2 \\; \\text{(Ising)}$$\n",
    "\n",
    "The active bonds are the ones we chose the term $\\delta_{\\sigma, \\sigma'}$; a (FK) cluster is a connected component of the graph formed by the active bonds. \n",
    "\n",
    "### Cluster algorithm (Swendsen Wang)\n",
    "The FK representation defines a joint distribution of cluster and spin configurations, $(C, \\sigma)$. We have the conditional probability\n",
    "\n",
    "$$\n",
    "P(\\sigma | C) = Q^{-\\text{number of clusters}} \\,,\\, \n",
    "$$\n",
    "\n",
    "if the $\\sigma$ is such that the sites of each FK cluster have the same spin. Otherwise $P(\\sigma|C) = 0$. So it is easy to sample $\\sigma$ given $C$: we choose a spin value for each FK cluster randomly and independently. \n",
    "\n",
    "Moreover it is also easy to sample $C$ given $\\sigma$. By Bayes rule\n",
    "\n",
    "$$\n",
    "P(C | \\sigma) \\propto w^{\\text{number of active bonds}} (1-w)^{\\text{number of inactive bonds}} \\,,\\, \n",
    "$$\n",
    "\n",
    "if the sites of each FK cluster have the same spin. Therefore, to sample $C$ given $\\sigma$, \n",
    "- all the bonds with disaligned spin must be inactive;\n",
    "- for each bond with aligned spin, it is acitve with probability $w$. \n",
    "\n",
    "The Monte Carlo algorithm starts from any configuration (say, of spin) $\\sigma_0$, samples a cluster configuration $C_1$ conditioned on it, and then sample a new spin configuration $\\sigma_1$ conditioned on $C_1$, so on and so forth. Compared to Metropolis Monte Carlo based on local updates, cluster algorithms (or loop algorithms) suffer less from the *critical slowdown*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some nice pictures first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = 6\n",
    "L = 2 ** lb\n",
    "full_graph, edges = prepare_graph(L)\n",
    "spin = np.zeros(L**2, dtype=int)\n",
    "w =  2 - 2 ** .5  # critical point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do 50 Monte Carlo updates \n",
    "for j in range(50):\n",
    "\n",
    "    same = (spin[edges.row] == spin[edges.col])  \n",
    "    \n",
    "    edges.data[:] = 0\n",
    "    edges.data[same] = (rnd.rand(np.sum(same)) < w) # same color: throw a dice\n",
    "   \n",
    "    FK_graph = edges.tocsc()\n",
    "    FK_graph.eliminate_zeros()\n",
    "    n_cl, FK_clusters = sp.csgraph.connected_components(FK_graph, directed=0, return_labels=1)\n",
    "    \n",
    "    FK_spin = rnd.randint(2, size = n_cl) * 2 - 1\n",
    "    spin[:] = FK_spin[FK_clusters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FK clusters takes lots of time to plot\n",
    "\n",
    "plot_FK = 1\n",
    "\n",
    "plt.figure(1, figsize = (6,6))\n",
    "plt.pcolor(spin.reshape(-1, L).T, cmap = \"RdBu\", vmin = -3, vmax = 1)\n",
    "xs, ys =  np.arange(L**2) // L, np.arange(L**2) % L\n",
    "if plot_FK:\n",
    "    for k, (i,j) in enumerate(zip(edges.row, edges.col)):\n",
    "        #diff = spin[1] \n",
    "        #d = edges.data[k]\n",
    "        if FK_clusters[i] != FK_clusters[j]: continue\n",
    "\n",
    "        z1, z2 = xs[i] +.5 + 1.j*(ys[i]+.5), (xs[j]+.5) + 1.j * (ys[j] + .5)\n",
    "        if abs(z1 - z2) > 2: continue\n",
    "        zm = (z1 +z2)/2\n",
    "        w1 = (z1 - zm) * 1.j + zm\n",
    "        w2 = 2 * zm - w1\n",
    "        plt.plot([z1.real, z2.real], [z1.imag, z2.imag], c = cmap(FK_clusters[i]/n_cl))\n",
    "plt.gca().set_aspect('equal')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spin spin correlation (two point function)\n",
    "\n",
    "Measure the two spin-spin correlation function in different phases (and with different system sizes). \n",
    "Describe the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_2p = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collect_data(w = [2 - 2 **.5], lbs = [6,7,8], N = 500, scale = \"log\", **kwargs):\n",
    "    \"\"\"\n",
    "    Routine to collect MC data\n",
    "    - w: coupling, from 0 (para) to 1 (ferro). Default: critical value\n",
    "    - lbs: a list of lb(system sizes). Default: [6,7,8]\n",
    "    - N: Monte Carlo update number. Default: 500\n",
    "    - scale: \"log\" or \"linear\". Default: log\n",
    "    \"\"\"\n",
    "    for lb in lbs:\n",
    "        L = 2 ** lb\n",
    "        print(\"L = %d\" % L)\n",
    "        full_graph, edges = prepare_graph(L)\n",
    "\n",
    "\n",
    "        if not (w, lb) in res_2p:\n",
    "            spin = rnd.randint(2, size = L ** 2)\n",
    "            if scale == \"log\":\n",
    "                rs = np.sort(np.hstack([2 ** np.arange(lb), 3 * 2 ** np.arange(lb-1)]))\n",
    "            else:\n",
    "                rs = np.arange(20)\n",
    "            ans = np.zeros(len(rs)+1,)\n",
    "            res_2p[w,lb] = (rs, ans, spin)\n",
    "        else:\n",
    "            rs, ans, spin = res_2p[w,lb]\n",
    "\n",
    "        #get spin clusters\n",
    "        for j in range(N):\n",
    "\n",
    "            # start from 4-state\n",
    "            same = (spin[edges.row] == spin[edges.col])  \n",
    "            #red = (spin[edges.row] + spin[edges.col] == 3)\n",
    "            edges.data[:] = 0\n",
    "            edges.data[same] = (rnd.rand(np.sum(same)) < w) # same color: throw a dice\n",
    "            #edges.data[red] = 1 # \n",
    "            FK_graph = edges.tocsc()\n",
    "            FK_graph.eliminate_zeros()\n",
    "            n_cl, FK_clusters = sp.csgraph.connected_components(FK_graph, directed=0, return_labels=1)\n",
    "\n",
    "            FK_spin = rnd.randint(2, size = n_cl) * 2 - 1\n",
    "            #FK_spin[np.unique(FK_clusters[ind_boundary])] *= 0\n",
    "            spin[:] = FK_spin[FK_clusters]\n",
    "            #print(n_cl, end = \" \")\n",
    "\n",
    "            # calculate 2p function\n",
    "            if ans[0] == 0 and j < 50: continue\n",
    "            for k,x in enumerate(rs):\n",
    "                intersect = (spin.reshape(L,L) * np.roll(spin.reshape(L,L), x, axis = 1))\n",
    "                ans[k+1] += (np.sum(intersect) / L ** 2)\n",
    "            ans[0] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paramagnetic phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w_p = 2 - 2 ** .5 - .1 # critical point\n",
    "collect_data(w = w_p, lbs = [5,6,7], scale = \"linear\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (w, lb), (rs, ans, spin) in res_2p.items():\n",
    "    if w != w_p: continue\n",
    "    ys = ans[1:] / ans[0]\n",
    "    errs = ans[1:] / ans[0] ** 1.5 * 2\n",
    "    plt.errorbar(rs, ys , marker=\"o\", label=\"$L=2^{%d}$\" % lb)\n",
    "    \n",
    "    plt.xlabel(\"$r$\")\n",
    "    plt.ylabel(r\"$\\left< \\sigma_{0,0} \\sigma_{r,0} \\right>$\")\n",
    "#plt.loglog(rs, rs ** (-1/4) / 1.5)\n",
    "plt.legend()\n",
    "#plt.yscale(\"log\")\n",
    "#plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ferromagnetic phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w_f = 2 - 2 ** .5 + .05 # critical point\n",
    "collect_data(w = w_f, lbs = [5,6,7], scale = \"linear\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (w, lb), (rs, ans, spin) in res_2p.items():\n",
    "    if w != w_f: continue\n",
    "    ys = ans[1:] / ans[0]\n",
    "    errs = ans[1:] / ans[0] ** 1.5 * 2\n",
    "    plt.errorbar(rs, ys , marker=\"o\", label=\"$L=2^{%d}$\" % lb)\n",
    "    \n",
    "    plt.xlabel(\"$r$\")\n",
    "    plt.ylabel(r\"$\\left< \\sigma_{0,0} \\sigma_{r,0} \\right>$\")\n",
    "#plt.loglog(rs, rs ** (-1/4) / 1.5)\n",
    "plt.legend()\n",
    "#plt.yscale(\"log\")\n",
    "#plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critical point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_c = 2 - 2 ** .5 # critical point\n",
    "collect_data(w = w_c, lbs = [5,6,7], N = 2000  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on the two point functions in different system sizes below. It is known by exact solution that the scaling dimension of the spin operator is $\\Delta_{\\sigma} = 1/8$ (we will see that in a later TD). Let us discover how this is related to the behavior of the two point function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for (w, lb), (rs, ans, spin) in res_2p.items():\n",
    "    if w != 2 - 2**.5: continue\n",
    "    ys = ans[1:] / ans[0]\n",
    "    errs = ans[1:] / ans[0] ** 1.5 * 2\n",
    "    plt.errorbar(rs, ys  , yerr = errs, marker=\"o\", label=\"$L=2^{%d}$\" % lb)\n",
    "    \n",
    "    plt.xlabel(\"$r$\")\n",
    "    plt.ylabel(r\"$\\left< \\sigma_{0,0} \\sigma_{r,0} \\right>$\")\n",
    "plt.loglog(rs, rs ** (-.125) / 1.5)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same data, plotted from a long-distance/field theory point of view. \n",
    "How do we collapse the data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (w, lb), (rs, ans, spin) in sorted(res_2p.items())[::-1]:\n",
    "    if w != 2 - 2**.5: continue\n",
    "    L =  2 ** lb\n",
    "    ys = ans[1:] / ans[0]\n",
    "    errs = ans[1:] / ans[0] ** 1.5 * 2\n",
    "    plt.errorbar(rs / L, ys  * L ** (.25), yerr = errs * L ** (.25), marker=\"o\", label=\"$L=2^{%d}$\" % lb)\n",
    "    \n",
    "    #plt.loglog(rs / L, ans[1:] / ans[0] , \"o-\", label=\"$L=2^{%d}$\" % lb )\n",
    "   \n",
    "    plt.xlabel(\"$r / L$\")\n",
    "    plt.ylabel(r\"$\\left<  \\sigma_{0,0} \\sigma_{r,0} \\right>  L^{2\\Delta}$\")\n",
    "plt.legend()\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quantity of the $y$ axis above is the two-point function of a *scaling operator*, which one may define \"experimentally\" as:\n",
    "### $$ \\sigma_{\\text{scaling}}(x) = \\sigma_{\\text{lattice}}(r = x  L) L^{\\Delta_{\\sigma}}$$\n",
    "\n",
    "One of the goals of this course is to understand how this formula emerges from the renormalization procedure.\n",
    "\n",
    "The rescaling of the operator is necessary to guarantee that the correlation function between scaling operators are independent of the lattice spacing (*scale invariant*) at the critical point.\n",
    "\n",
    "- Is this achievable away from the critical point?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epilogue: from Ising to percolation\n",
    "\n",
    "- Show that the spin-spin correlation function is equal to the probability that the two sites are on the same FK cluster:\n",
    "\n",
    "$$ \\left< \\sigma_x \\sigma_{x'} \\right> = \\mathbb{P}(\\text{$x$, $x'$ on the same FK cluster})$$\n",
    "\n",
    "- Consider the FK partition function with $Q=1$. Argue that it describes bond percolation on the square lattice. What is the analogue of spin-spin correlation in percolation?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
