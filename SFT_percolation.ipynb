{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BEGIN\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc('font', **{ \"size\":16}) #**{,,'serif':['Palatino']\n",
    "rc('text', usetex=True)\n",
    "import numpy.random as rnd\n",
    "rnd.seed()\n",
    "import scipy.sparse as sp\n",
    "import scipy.sparse.linalg as sla\n",
    "import scipy.linalg as la\n",
    "import pickle as cp\n",
    "import scipy.optimize as opt\n",
    "from scipy.optimize import curve_fit as fit\n",
    "#import mps\n",
    "import cProfile\n",
    "import subprocess\n",
    "from scipy.special import hyp2f1, erf\n",
    "from scipy.optimize import brentq\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def percolate(field, h):\n",
    "    pos =  field <= h # sign cluster\n",
    "    mask = np.where((pos).reshape(-1))[0]\n",
    "    #print(len(mask))\n",
    "    active_graph = full_graph[mask,:]\n",
    "    active_graph = active_graph[:, mask]\n",
    "    n_components, labels = sp.csgraph.connected_components(active_graph, directed=0, return_labels=1)\n",
    "    #topset = set(labels[mask < L])\n",
    "    \n",
    "    return len(set(labels[mask < L]).intersection(labels[mask > (L**2-L)])) \n",
    "\n",
    "def gethc(field, precision = 1e-2, **kwargs ):\n",
    "    lo, hi = np.min(field), np.max(field)\n",
    "    while hi - lo > precision:\n",
    "        mi = (hi + lo)/2\n",
    "        if percolate(field, mi):\n",
    "            hi = mi\n",
    "        else:\n",
    "            lo = mi\n",
    "    return (hi + lo)/2\n",
    "\n",
    "def frac_laplacian(L,ratio = 1, H = 0., **kwargs): \n",
    "    L1 = int(L * ratio)\n",
    "    ps = np.sin(np.arange(L) / L * np.pi) * L\n",
    "    qs = np.sin(np.arange(L1) / L1 * np.pi) * L1\n",
    "    \n",
    "    ps, qs = np.meshgrid(ps, qs)\n",
    "    laplacian = (ps ** 2 + qs ** 2) \n",
    "    laplacian[0,0] = 1\n",
    "    laplacian **= (-H/2 - 1/2)\n",
    "    laplacian[0,0] = 0. \n",
    "    mini = np.sum(laplacian[::2, ::2] + laplacian[1::2, 1::2] \n",
    "                  - laplacian[1::2, ::2] - laplacian[::2, 1::2])\n",
    "    #laplacian[0,0] = -mini \n",
    "    return laplacian\n",
    "def get_var(L, H = 0):\n",
    "    laplacian = frac_laplacian(L, H)\n",
    "    return np.sum(laplacian ** 2)\n",
    "def prepare_graph(L, ratio = 1, cut_boundary = 1, bond_perco = 1, **kwargs):\n",
    "    xy2i = lambda x,y:x*L + y\n",
    "    L1 = int(L * ratio) \n",
    "    xs, ys =  np.arange(L* L1) // L, np.arange(L* L1) % L\n",
    "    eps = (xs + ys) % 2 * 2 - 1\n",
    "    xp, xm = (xs + 1) % L1, (xs - 1) % L1\n",
    "    yp, ym = (ys + 1) % L, (ys - 1) % L\n",
    "    # this is bond percolation on the square lattice\n",
    "    connec = 6 if bond_perco else 4\n",
    "    if bond_perco:\n",
    "        inds = np.hstack((\n",
    "            xy2i(xp, ys), xy2i(xm, ys), \n",
    "            xy2i(xs , yp), xy2i(xs , ym), \n",
    "            xy2i(xp, (ys + eps) % L), xy2i(xm,  (ys - eps) % L), \n",
    "            )).reshape(connec, -1).T.reshape(-1)\n",
    "    else:\n",
    "        inds = np.hstack((\n",
    "            xy2i(xp, ys), xy2i(xm, ys), \n",
    "            xy2i(xs , yp), xy2i(xs , ym)\n",
    "            )).reshape(connec, -1).T.reshape(-1)\n",
    "    data = np.ones_like(inds, dtype=int)\n",
    "    indptr = np.arange(L * L1 + 1) * connec\n",
    "    full_graph = sp.csc_matrix((data, inds, indptr),shape=(L*L1, L*L1))\n",
    "   # print(len(full_graph.data))\n",
    "    # remove the edges of one periodic boundary\n",
    "    if cut_boundary:\n",
    "        lil = full_graph.tolil()\n",
    "        lil[:L, -L:] = 0\n",
    "        lil[-L:, :L] = 0\n",
    "        if cut_boundary > 1:\n",
    "            # in this case cut both periodicity\n",
    "            lil[::L, L-1::L] = 0\n",
    "            lil[L-1::L, ::L] = 0\n",
    "        full_graph = lil.tocsc()\n",
    "    return full_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percolation transition\n",
    "\n",
    "We study numerically the bond percolation on a square lattice. Every bond is activated with probability $p$. A percolation transition takes place at a threshold $p_c$: in the infinite system limit, there exists an \"infinite cluster\" (*cluser* means connected component in percolation jargon) with probability $1$ if $p > p_c$, and with probability $0$ if $p < p_c$. \n",
    "\n",
    "The value of $p_c$ depends on the microscopic details and is not universal. For the bond percolation on the square lattice, one can show by a duality argument that $p_c = 1/2$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nice pictures first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 64\n",
    "full_graph = prepare_graph(L, bond_perco=1, cut_boundary = 2)\n",
    "field = rnd.rand(L,L)\n",
    "fig, ax = plt.subplots(2,3, figsize = (8,5.3), sharex=\"all\", sharey=\"all\")\n",
    "for k,p in enumerate( [.4, .5, .6]):\n",
    "    \n",
    "    pos = field <= p\n",
    "    mask = np.where((pos).reshape(-1))[0]\n",
    "    #print(len(mask))\n",
    "    active_graph = full_graph[mask,:]\n",
    "    active_graph = active_graph[:, mask]\n",
    "    n_components, labels = sp.csgraph.connected_components(active_graph, directed=0, return_labels=1)\n",
    "    plt.sca(ax[0, k])\n",
    "    plt.pcolor(pos.reshape(L,L), cmap='RdBu', vmax=1, vmin=-1)\n",
    "    #plt.yticks([])\n",
    "    #plt.xticks([])\n",
    "    plt.sca(ax[1, k])\n",
    "    \n",
    "    h, b = np.histogram(labels, bins = np.arange(n_components+1)-.5)\n",
    "    max_ind = np.argmax(h)\n",
    "    \n",
    "    max_comp = np.zeros(L**2)\n",
    "    max_comp[mask[labels==max_ind]] = 1\n",
    "    \n",
    "    plt.pcolor((max_comp).reshape(L, L), cmap=\"RdBu\",  vmax=1, vmin=-1)\n",
    "    #plt.yticks([])\n",
    "    #plt.xticks([])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $p=0.4, 0.5, 0.6$ (left, middle, right), we plot the activated bonds (top row) and the largest cluster (bottom row). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infinite cluster: finite size scaling\n",
    "\n",
    "The probability of having an infinite cluster has a sharp jump only in the thermodynamic limit. \n",
    "For finite systems, we need to first define what an infinite cluster means. One way is to consider a square lattice with open boundary condition, and ask whether the top and the bottom are connected. If so, we say there is an infinite cluster\n",
    "\n",
    "With this definition, one can measure the existence probability of an infinite cluster as a function of $p$ (and as always, of the system size $L$),\n",
    "\n",
    "### $$P_\\infty(p) := \\text{existence probability of infinite cluster at $p$ }$$\n",
    "\n",
    "Then we will perform a critical scaling. \n",
    "\n",
    "*The method used below is a standard trick among numericists, but is not that important for our purposes. Basically, instead of flipping a coin for each bond, we order the bonds randomly, and activate them one by one. Then at some (random) threshold fraction $q$ of activated bonds, an infinite cluster will appear. It is not hard to convince oneself that*\n",
    "#### $$\\mathrm{Prob}(q < p) = \\mathbb{P}_{\\infty}(p)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_hc = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for L in [16, 32, 64]:\n",
    "    full_graph = prepare_graph(L, bond_perco=1, cut_boundary = 2)\n",
    "    for rep in range(500):\n",
    "        #if H == -1:\n",
    "        field = rnd.rand(L,L)\n",
    "        if (L) not in res_hc:\n",
    "            res_hc[L] = []\n",
    "        hc = gethc(field)\n",
    "        p = np.mean(field < hc)\n",
    "        res_hc[L].append(p)\n",
    "        if rep % 100 == 0:  \n",
    "            print(\".\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (L), pcs in res_hc.items():\n",
    "\n",
    "    if len(pcs) > 0:\n",
    "        \n",
    "        plt.plot( (np.sort(pcs) ) ,  \n",
    "                   np.linspace(0, 1,len( pcs)), label = \"$L = %d$\" % L) # / norm ** .5\n",
    "plt.legend()\n",
    "plt.xlabel(r\"$p$\")\n",
    "plt.ylabel(r\"$P_{\\infty}(p)$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (L), pcs in res_hc.items():\n",
    "\n",
    "    if len(pcs) > 0:\n",
    "        \n",
    "        plt.plot( (np.sort(pcs) - .5) * L ** (3/4) ,  \n",
    "                   np.linspace(0, 1,len( pcs)), label = \"$L = %d$\" % L) # / norm ** .5\n",
    "plt.legend()\n",
    "plt.xlabel(r\"$(p - p_c) L^{1/\\nu}$\")\n",
    "plt.ylabel(r\"$P_{\\infty}(p)$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The finite size scaling confirmed the correlation length exponent \n",
    "$$\\nu = 4/3$$\n",
    "for the 2D percolation transition. (This is an exact result, but requires a good deal of conformal field theory to understand.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One point function \n",
    "\n",
    "From the illustration above, it is tempting to consider the size of the largest cluster, $S_{\\max}$ as a probe of the transition: when $p> p_c$, we expect $S_{\\max} / L^2$ to tend to a constant, or in other words, a nonzero portion $m$ of points belong to a same cluster. This portion is the analogue of the spontaneous magnetization in the Ising model (in the ferromagnetic phase). As in the Ising model, its critical scaling involves another independent exponent: \n",
    "### $$ \\Delta_{\\sigma} = 5/48 $$\n",
    "Again, this is a nontrivial prediction of conformal field theory.\n",
    "\n",
    "Below we test this prediction by measureing $m$ near the critical point, on the percolating side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = np.linspace(.5, .6, 13)\n",
    "Ls = 2 ** np.arange(4, 7)\n",
    "res_sizes = dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for L in Ls:\n",
    "    ######################################\n",
    "    #construct the graph\n",
    "    full_graph = prepare_graph(L, bond_perco=1, cut_boundary=0)\n",
    "\n",
    "\n",
    "    for rep in range(500):\n",
    "        field = rnd.rand(L,L)\n",
    "\n",
    "        for h in hs:\n",
    "            pos =  field <= h\n",
    "            mask = np.where((pos).reshape(-1))[0]\n",
    "   \n",
    "            active_graph = full_graph[mask,:]\n",
    "            active_graph = active_graph[:, mask]\n",
    "            n_components, labels = sp.csgraph.connected_components(active_graph, directed=0, return_labels=1)\n",
    "           \n",
    "            his, b = np.histogram(labels, bins = np.arange(n_components+1)-.5)\n",
    "            ans = np.max(his) / L ** 2\n",
    "\n",
    "            if (L,h) not in res_sizes:\n",
    "                res_sizes[L,h] = [ans]\n",
    "            else:\n",
    "                res_sizes[L,h].append(ans)\n",
    "\n",
    "        if rep % 100 == 0: print('.', end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for L in Ls:\n",
    "    Hs = []\n",
    "    Ms = []\n",
    "    Es = []\n",
    "    for h in hs:\n",
    "        if (L,h) in res_sizes:\n",
    "            data = res_sizes[L,h]\n",
    "            Ms.append(np.mean(data))\n",
    "            Es.append(np.std(data) / len(data) ** .5 * 2)\n",
    "            Hs.append(h )\n",
    "    if len(Hs):\n",
    "        Hs = np.array(Hs)\n",
    "        plt.errorbar(Hs , Ms, yerr=Es, marker=\"o\", linestyle=\"-\", label=\"$L=%d$\" % L, markersize=4)\n",
    "plt.legend()    \n",
    "plt.xlabel(r\"$p$\")\n",
    "plt.ylabel(r\"$m$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for L in Ls:\n",
    "    Hs = []\n",
    "    Ms = []\n",
    "    Es = []\n",
    "    for h in hs:\n",
    "        if (L,h) in res_sizes:\n",
    "            data = res_sizes[L,h]\n",
    "            Ms.append(np.mean(data))\n",
    "            Es.append(np.std(data) / len(data) ** .5 * 2)\n",
    "            Hs.append(h )\n",
    "    if len(Hs):\n",
    "        Hs = np.array(Hs)\n",
    "        plt.errorbar((Hs - 1/2) * L ** (3/4) , np.array(Ms) * L ** (5/48), yerr=Es, marker=\"o\", linestyle=\"-\", label=\"$L=%d$\" % L, markersize=4)\n",
    "plt.legend()    \n",
    "plt.xlabel(r\"$(p - p_c) L^{1/\\nu}$\")\n",
    "plt.ylabel(r\"$m L^{\\Delta_{\\sigma}}$\")\n",
    "#plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make an argument for the following hyperscaling relation\n",
    "### $$ m_{L\\to\\infty} \\sim |p-p_c|^{\\nu \\Delta_{\\sigma}}$$\n",
    "\n",
    "- Back-of-the-envelope \"dimensional analysis\": $m \\sim L^{-\\Delta_\\sigma}$, $L \\sim |p-p_c|^{-\\nu}$\n",
    "\n",
    "- Slightly more savant: start from single variable scaling $m  = L^{-\\Delta_\\sigma} f((p-p_c) L^{1/v}) $, and consider the limit $L \\to \\infty$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two point function\n",
    "\n",
    "Recall in Ising that another way to probe the $\\Delta_\\sigma$ exponent is to consider the spin-spin correlation function. In percolation, we consider the probability that two points are in a same cluster (connectivity). Why? This has to do with the Kasterleyn Fortuin representation, which smoothly interpolates between Ising ($Q=2$ Potts) and percolation ($Q \\to 1$ Potts, believe it or not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_2p = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for nL in range(4, 8):\n",
    "    print(nL)\n",
    "    L = 2 ** nL\n",
    "    full_graph = prepare_graph(L, bond_perco=1, cut_boundary=0)\n",
    "    #print(len(full_graph.data))\n",
    "    ##\n",
    "    if L in res_2p:\n",
    "        rs, ans = res_2p[L]\n",
    "    else:\n",
    "        rs = 2 ** np.arange(nL)\n",
    "        ans = np.zeros(len(rs) + 1, dtype=float)\n",
    "        res_2p[L] = (rs,ans)\n",
    "    for rep in range(100):\n",
    "        print(\".\", end=\"\")\n",
    "        field = rnd.rand(L,L) * 2 - 1\n",
    "        pos =  field <= 0 \n",
    "        mask = np.where((pos).reshape(-1))[0]\n",
    "        #print(len(mask))\n",
    "        active_graph = full_graph[mask,:]\n",
    "        active_graph = active_graph[:, mask]\n",
    "        n_components, labels = sp.csgraph.connected_components(active_graph, directed=0, return_labels=1)\n",
    "        label_real = -np.ones(L ** 2, dtype=int) \n",
    "        label_real[mask] = labels \n",
    "        label_real = label_real.reshape(L, -1)\n",
    "        for j,x in enumerate(rs):\n",
    "            intersect = (label_real ==  np.roll(label_real, x, axis = 1)) * (label_real >= 0)    \n",
    "            ans[j+1] += (np.sum(intersect) / L ** 2)\n",
    "        ans[0] += 1\n",
    "    \n",
    "   # plt.plot( (ans[1:] / ans[0]) ** -2, \"o-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for L, (rs, ans) in res_2p.items():\n",
    "    plt.loglog(rs, ans[1:] / ans[0], \"o-\", label=\"$L=%d$\" % L)\n",
    "plt.plot(rs, rs ** (-5/24) * ans[1] / ans[0] / 1.1, \"--\", label = \"$\\propto r^{-2\\Delta_{\\sigma}}$\")\n",
    "plt.legend(bbox_to_anchor = (1,1))\n",
    "plt.xlabel(\"$r$\")\n",
    "plt.ylabel(\"$P_2(r)$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (for fun) Distribution of cluster sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 256\n",
    "full_graph = prepare_graph(L, bond_perco=1, cut_boundary = 2)\n",
    "Sizes = np.array([])\n",
    "for j in range(100):\n",
    "    mask = np.where(rnd.rand(L**2) < .5)[0]\n",
    "    #print(len(mask))\n",
    "    active_graph = full_graph[mask,:]\n",
    "    active_graph = active_graph[:, mask]\n",
    "    n_components, labels = sp.csgraph.connected_components(active_graph, directed=0, return_labels=1)\n",
    "    sizes, b = np.histogram(labels, bins = np.arange(n_components+1)-.5)\n",
    "    Sizes = np.hstack([Sizes, sizes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,b = np.histogram(np.log(Sizes), bins = 20, density=1)\n",
    "b = np.exp(b)\n",
    "plt.loglog(b[1:], h, \"o\")\n",
    "plt.plot(b, b ** ( -1 + 5/24) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
